{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import io\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from models.modeling import VisionTransformer, CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"attention_data\", exist_ok=True)\n",
    "if not os.path.isfile(\"attention_data/imagenet_labels.txt\"):\n",
    "\turlretrieve(\n",
    "\t\turl=\"https://storage.googleapis.com/bit_models/ilsvrc2012_wordnet_lemmas.txt\",\n",
    "\t\tfilename=\"attention_data/imagenet_labels.txt\",\n",
    "\t)\n",
    "if not os.path.isfile(\"attention_data/ViT-B_16-224.npz\"):\n",
    "\turlretrieve(\n",
    "\t\turl=\"https://storage.googleapis.com/vit_models/imagenet21k+imagenet2012/ViT-B_16-224.npz\",\n",
    "\t\tfilename=\"attention_data/ViT-B_16-224.npz\",\n",
    "\t)\n",
    "imagenet_labels = dict(enumerate(open('attention_data/imagenet_labels.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Image\n",
    "# img_url = \"https://as1.ftcdn.net/v2/jpg/01/63/53/20/1000_F_163532024_yuon7OJQYn8gnzTQpjXKKtO69XhF9SWx.jpg\"\n",
    "# img_url = \"https://as2.ftcdn.net/v2/jpg/01/67/24/45/1000_F_167244514_0AcAa9opIWbbuNi4jxgmT7nw6fkPTFqJ.jpg\"\n",
    "# img_url = \"https://as1.ftcdn.net/v2/jpg/02/94/68/58/1000_F_294685879_tFywW5pdkCVdQM11ALrxClXJqibJimSS.jpg\"\n",
    "# img_url = \"https://www.finna.fi/Cover/Show?source=Solr&id=sa-kuva.sa-kuva-63836\"\n",
    "# img_url = \"https://www.finna.fi/Cover/Show?source=Solr&id=sa-kuva.sa-kuva-23125\"\n",
    "# img_url = \"https://www.finna.fi/Cover/Show?source=Solr&id=sa-kuva.sa-kuva-105292\"\n",
    "img_url = \"https://www.finna.fi/Cover/Show?source=Solr&id=sa-kuva.sa-kuva-89881\"\n",
    "urlretrieve(url=img_url, filename=\"attention_data/img.jpg\")\n",
    "\n",
    "# Prepare Model\n",
    "config = CONFIGS[\"ViT-B_16\"]\n",
    "model = VisionTransformer(config, num_classes=1000, zero_head=False, img_size=224, vis=True)\n",
    "model.load_from(np.load(\"attention_data/ViT-B_16-224.npz\"))\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose(\n",
    "  [\n",
    "\t\ttransforms.Resize((224, 224)),\n",
    "\t\ttransforms.ToTensor(),\n",
    "\t\ttransforms.Normalize(\n",
    "\t\t\tmean=[0.5, 0.5, 0.5], \n",
    "\t\t\tstd=[0.5, 0.5, 0.5]\n",
    "\t\t),\n",
    "\t]\n",
    ")\n",
    "im = Image.open(\"attention_data/img.jpg\")\n",
    "x = transform(im)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, att_mat = model(x.unsqueeze(0))\n",
    "\n",
    "att_mat = torch.stack(att_mat).squeeze(1)\n",
    "\n",
    "# Average the attention weights across all heads.\n",
    "att_mat = torch.mean(att_mat, dim=1)\n",
    "\n",
    "# To account for residual connections, we add an identity matrix to the\n",
    "# attention matrix and re-normalize the weights.\n",
    "residual_att = torch.eye(att_mat.size(1))\n",
    "aug_att_mat = att_mat + residual_att\n",
    "aug_att_mat = aug_att_mat / aug_att_mat.sum(dim=-1).unsqueeze(-1)\n",
    "\n",
    "# Recursively multiply the weight matrices\n",
    "joint_attentions = torch.zeros(aug_att_mat.size())\n",
    "joint_attentions[0] = aug_att_mat[0]\n",
    "\n",
    "for n in range(1, aug_att_mat.size(0)):\n",
    "\t\tjoint_attentions[n] = torch.matmul(aug_att_mat[n], joint_attentions[n-1])\n",
    "\t\t\n",
    "# Attention from the output token to the input space.\n",
    "v = joint_attentions[-1]\n",
    "grid_size = int(np.sqrt(aug_att_mat.size(-1)))\n",
    "mask = v[0, 1:].reshape(grid_size, grid_size).detach().numpy()\n",
    "mask = cv2.resize(mask / mask.max(), im.size)[..., np.newaxis]\n",
    "result = (mask * im).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(16, 14))\n",
    "\n",
    "ax1.set_title('Original')\n",
    "ax1.axis('off')\n",
    "ax2.set_title('Attention Map')\n",
    "ax2.axis('off')\n",
    "_ = ax1.imshow(im)\n",
    "_ = ax2.imshow(result)\n",
    "\n",
    "probs = torch.nn.Softmax(dim=-1)(logits)\n",
    "topK = torch.argsort(probs, dim=-1, descending=True)\n",
    "print(probs.shape, topK.shape)\n",
    "print(\"Prediction Label and Attention Map!\\n\")\n",
    "for idx in topK[0, :5]:\n",
    "\tprint(f'{probs[0, idx.item()]:.5f} : {imagenet_labels[idx.item()]}', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "* [attention_flow](https://github.com/samiraabnar/attention_flow)\n",
    "* [vit-keras](https://github.com/faustomorales/vit-keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate(joint_attentions):\n",
    "\t\t# Attention from the output token to the input space.\n",
    "\t\tmask = v[0, 1:].reshape(grid_size, grid_size).detach().numpy()\n",
    "\t\tmask = cv2.resize(mask / mask.max(), im.size)[..., np.newaxis]\n",
    "\t\tresult = (mask * im).astype(\"uint8\")\n",
    "\n",
    "\t\tfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(16, 16))\n",
    "\t\tax1.set_title('Original')\n",
    "\t\tax2.set_title('Attention Map_%d Layer' % (i+1))\n",
    "\t\t_ = ax1.imshow(im)\n",
    "\t\t_ = ax2.imshow(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
